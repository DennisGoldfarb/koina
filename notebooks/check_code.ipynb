{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEQ_LEN = 30  # Sequence length for prosit\n",
    "VEC_LENGTH = 174\n",
    "def create_masking(charges_array, sequences_lengths):\n",
    "    \"\"\"\n",
    "    assume reshaped output of prosit, shape sould be (num_seq, 174)\n",
    "    set filtered output where not allowed positions are set to -1\n",
    "    prosit output has the form:\n",
    "    y1+1 y1+2 y1+3 b1+1 b1+2 b1+3 y2+1     y2+2 y2+3     b2+1     b2+2 b2+3\n",
    "    if charge >= 3: all allowed\n",
    "    if charge == 2: all +3 invalid\n",
    "    if charge == 1: all +2 & +3 invalid\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(charges_array) == len(sequences_lengths)\n",
    "\n",
    "    mask = np.ones(shape=(len(charges_array), VEC_LENGTH), dtype=np.float16)\n",
    "    \n",
    "    for i in range(len(charges_array)):\n",
    "        charge_one_hot = charges_array[i]\n",
    "        len_seq = sequences_lengths[i]\n",
    "        m = mask[i]\n",
    "\n",
    "        # filter according to peptide charge\n",
    "        if np.array_equal(charge_one_hot, [1, 0, 0, 0, 0, 0]):\n",
    "            invalid_indexes = [(x * 3 + 1) for x in range((SEQ_LEN - 1) * 2)] + [\n",
    "                (x * 3 + 2) for x in range((SEQ_LEN - 1) * 2)\n",
    "            ]\n",
    "            m[invalid_indexes] = np.nan\n",
    "\n",
    "        elif np.array_equal(charge_one_hot, [0, 1, 0, 0, 0, 0]):\n",
    "            invalid_indexes = [x * 3 + 2 for x in range((SEQ_LEN - 1) * 2)]\n",
    "            m[invalid_indexes] = np.nan\n",
    "\n",
    "        if len_seq < SEQ_LEN:\n",
    "            invalid_indexes = range((len_seq - 1) * 6, VEC_LENGTH)\n",
    "            m[invalid_indexes] = np.nan\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def sum(a,b):\n",
    "    c = a + b\n",
    "    return c, a\n",
    "\n",
    "ss = sum(1,2)\n",
    "print(ss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan nan  1. nan nan  1. nan nan  1. nan nan  1. nan nan  1. nan nan\n",
      "   1. nan nan  1. nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [ 1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan\n",
      "   1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan\n",
      "   1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan\n",
      "   1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan  1.  1. nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "charges_array = [[1, 0, 0, 0, 0, 0],[0, 1, 0, 0, 0, 0]]\n",
    "sequences_lengths = [5,13]\n",
    "mask = create_masking(charges_array, sequences_lengths)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from spectrum_fundamentals.annotation.annotation import peak_pos_xl_cms2\n",
    "\n",
    "VEC_LENGTH = 174 * 2\n",
    "\n",
    "\n",
    "def peak_pos_xl_cms2(unmod_seq: str, crosslinker_position: int) -> list:\n",
    "    \"\"\"\n",
    "    Determines the positions of all potential normal and xl fragments within the vector generated by generate_annotation_matrix.\n",
    "\n",
    "    This fuction is used only for cleavable crosslinked peptides.\n",
    "\n",
    "    :param unmod_seq: Un modified peptide sequence\n",
    "    :param crosslinker_position: The position of crosslinker\n",
    "    :raises ValueError: if Peptides exceeding a length of 30.\n",
    "    :return: position of diffrent fragments as list\n",
    "    \"\"\"\n",
    "    peaks_y = []\n",
    "    peaks_b = []\n",
    "    peaks_yshort = []\n",
    "    peaks_bshort = []\n",
    "    peaks_ylong = []\n",
    "    peaks_blong = []\n",
    "\n",
    "    if len(unmod_seq) < 31:\n",
    "        if crosslinker_position != 1:\n",
    "            peaks_b = np.array([3, 4, 5])\n",
    "            peaks_b = np.tile(peaks_b, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "            first_pos_ylong = (\n",
    "                (len(unmod_seq) - crosslinker_position) * 6\n",
    "            ) + 174  # fisrt  position for ylong\n",
    "            peaks_ylong = np.arange(first_pos_ylong, first_pos_ylong + 3)\n",
    "            peaks_ylong = np.tile(peaks_ylong, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "\n",
    "        if len(unmod_seq) != crosslinker_position:\n",
    "            peaks_y = [0, 1, 2]\n",
    "            peaks_y = np.tile(\n",
    "                peaks_y, len(unmod_seq) - crosslinker_position\n",
    "            ) + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            first_pos_blong = (\n",
    "                ((crosslinker_position - 1) * 6) + 174 + 3\n",
    "            )  # fisrt  position for blong\n",
    "            peaks_blong = [first_pos_blong, first_pos_blong + 1, first_pos_blong + 2]\n",
    "            peaks_blong = np.arange(first_pos_blong, first_pos_blong + 3)\n",
    "            peaks_blong = list(\n",
    "                np.tile(peaks_blong, len(unmod_seq) - crosslinker_position)\n",
    "                + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            )\n",
    "\n",
    "        peaks_yshort = [x - 174 for x in peaks_ylong]\n",
    "        peaks_bshort = [x - 174 for x in peaks_blong]\n",
    "        peaks_range = (\n",
    "            list(peaks_y)\n",
    "            + list(peaks_b)\n",
    "            + list(peaks_yshort)\n",
    "            + list(peaks_bshort)\n",
    "            + list(peaks_ylong)\n",
    "            + list(peaks_blong)\n",
    "        )\n",
    "        peaks_range.sort()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Peptides exceeding a length of 30 are not supported: {len(unmod_seq)}\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        peaks_range,\n",
    "        peaks_y,\n",
    "        peaks_b,\n",
    "        peaks_yshort,\n",
    "        peaks_bshort,\n",
    "        peaks_ylong,\n",
    "        peaks_blong,\n",
    "    )\n",
    "\n",
    "def create_masking(unmod_seq, crosslinker_position):\n",
    "    \"\"\"\n",
    "    assume reshaped output of xl-prosit, shape sould be (num_seq, 174 * 2)\n",
    "    set filtered output where not allowed positions are set to -1\n",
    "    we set charge = 2 for all peptide a and b\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(unmod_seq) == len(crosslinker_position)\n",
    "    mask = np.ones(shape=(len(unmod_seq), VEC_LENGTH))\n",
    "    for i in range(len(unmod_seq)):\n",
    "        m = mask[i].copy()\n",
    "        peaks_ranges = peak_pos_xl_cms2(unmod_seq[i], crosslinker_position[i])\n",
    "        updated_mask  = np.setdiff1d(np.arange(0, 348), peaks_ranges[0])\n",
    "        #print(peaks_ranges[0])\n",
    "        #print(updated_mask)\n",
    "        #print(m)\n",
    "        m[updated_mask] = np.nan\n",
    "        mask[i] = m\n",
    "    return mask\n",
    "\n",
    "def apply_masking(peaks, mask):\n",
    "    peaks[peaks < 0] = np.finfo(np.float32).eps\n",
    "    out = np.multiply(peaks, mask)\n",
    "    out = (out.T / np.nanmax(out, axis=1)).T\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan  1.  1.  1.\n",
      "  nan nan nan  1.  1.  1. nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan  1.  1.  1. nan nan nan\n",
      "   1.  1.  1. nan nan nan  1.  1.  1. nan nan nan  1.  1.  1. nan nan nan\n",
      "   1.  1.  1. nan nan nan  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "unmod_seq = [\"KKD\",\"KDDFKKK\"]\n",
    "crosslinker_position = [1,7]\n",
    "mask = create_masking(unmod_seq, crosslinker_position)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr1 = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "arr2 = np.array([2, 4, 5])\n",
    "\n",
    "result = np.setdiff1d(arr1, arr2)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y1+1' 'y1+2' 'y1+3' 'b1+1' 'b1+2' 'b1+3' 'y2+1' 'y2+2' 'y2+3' 'b2+1'\n",
      " 'b2+2' 'b2+3' 'y3+1' 'y3+2' 'y3+3' 'b3+1' 'b3+2' 'b3+3' 'y4+1' 'y4+2'\n",
      " 'y4+3' 'b4+1' 'b4+2' 'b4+3' 'y5+1' 'y5+2' 'y5+3' 'b5+1' 'b5+2' 'b5+3'\n",
      " 'y6+1' 'y6+2' 'y6+3' 'b6+1' 'b6+2' 'b6+3' 'y7+1' 'y7+2' 'y7+3' 'b7+1'\n",
      " 'b7+2' 'b7+3' 'y8+1' 'y8+2' 'y8+3' 'b8+1' 'b8+2' 'b8+3' 'y9+1' 'y9+2'\n",
      " 'y9+3' 'b9+1' 'b9+2' 'b9+3' 'y10+1' 'y10+2' 'y10+3' 'b10+1' 'b10+2'\n",
      " 'b10+3' 'y11+1' 'y11+2' 'y11+3' 'b11+1' 'b11+2' 'b11+3' 'y12+1' 'y12+2'\n",
      " 'y12+3' 'b12+1' 'b12+2' 'b12+3' 'y13+1' 'y13+2' 'y13+3' 'b13+1' 'b13+2'\n",
      " 'b13+3' 'y14+1' 'y14+2' 'y14+3' 'b14+1' 'b14+2' 'b14+3' 'y15+1' 'y15+2'\n",
      " 'y15+3' 'b15+1' 'b15+2' 'b15+3' 'y16+1' 'y16+2' 'y16+3' 'b16+1' 'b16+2'\n",
      " 'b16+3' 'y17+1' 'y17+2' 'y17+3' 'b17+1' 'b17+2' 'b17+3' 'y18+1' 'y18+2'\n",
      " 'y18+3' 'b18+1' 'b18+2' 'b18+3' 'y19+1' 'y19+2' 'y19+3' 'b19+1' 'b19+2'\n",
      " 'b19+3' 'y20+1' 'y20+2' 'y20+3' 'b20+1' 'b20+2' 'b20+3' 'y21+1' 'y21+2'\n",
      " 'y21+3' 'b21+1' 'b21+2' 'b21+3' 'y22+1' 'y22+2' 'y22+3' 'b22+1' 'b22+2'\n",
      " 'b22+3' 'y23+1' 'y23+2' 'y23+3' 'b23+1' 'b23+2' 'b23+3' 'y24+1' 'y24+2'\n",
      " 'y24+3' 'b24+1' 'b24+2' 'b24+3' 'y25+1' 'y25+2' 'y25+3' 'b25+1' 'b25+2'\n",
      " 'b25+3' 'y26+1' 'y26+2' 'y26+3' 'b26+1' 'b26+2' 'b26+3' 'y27+1' 'y27+2'\n",
      " 'y27+3' 'b27+1' 'b27+2' 'b27+3' 'y28+1' 'y28+2' 'y28+3' 'b28+1' 'b28+2'\n",
      " 'b28+3' 'y29+1' 'y29+2' 'y29+3' 'b29+1' 'b29+2' 'b29+3']\n"
     ]
    }
   ],
   "source": [
    "#import triton_python_backend_utils as pb_utils\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def gen_annotation():\n",
    "    ions = [\n",
    "        \"y\",\n",
    "        \"b\",\n",
    "    ]\n",
    "    charges = [1, 2, 3]\n",
    "    positions = [x for x in range(1, 30)]\n",
    "    annotation = []\n",
    "    for pos in positions:\n",
    "        for ion in ions:\n",
    "            for charge in charges:\n",
    "                annotation.append(f\"{ion}{pos}+{charge}\")\n",
    "    return np.array(annotation).astype(np.object_)\n",
    "gen_annotation = gen_annotation()\n",
    "print(gen_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          text_column  position\n",
      "0     AAMK[UNIMOD:26]         4\n",
      "1   K[UNIMOD:24]AACKK         1\n",
      "2  CMKKK[UNIMOD:26]DD         5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'text_column': [\n",
    "        \"AAM[UNIMOD:35]K[UNIMOD:26]\",\n",
    "        \"K[UNIMOD:24]AAC[UNIMOD:5]KK\",\n",
    "        \"C[UNIMOD:5]M[UNIMOD:35]KKK[UNIMOD:26]DD\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove \"[UNIMOD:35]\" and \"[UNIMOD:5]\" from the \"text_column\"\n",
    "df[\"text_column\"] = df[\"text_column\"].str.replace(r\"\\[UNIMOD:35\\]|\\[UNIMOD:5\\]\", \"\", regex=True)\n",
    "df['position'] = df['text_column'].apply(lambda x: re.search(r'K\\[[^\\]]*\\]', x).start() + 1)\n",
    "# Display the modified DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                column_name  position\n",
      "0            K[UNIMOD:26]KK         1\n",
      "1  KKKKKKKK[UNIMOD:24]AACKK         8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Assuming your DataFrame column is named 'column_name'\n",
    "data = {'column_name': ['K[UNIMOD:26]KK', 'KKKKKKKK[UNIMOD:24]AACKK']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Find the position of 'K' connected to '[UNIMOD:26]' or '[UNIMOD:24]' after removing the tags\n",
    "df['position'] = df['column_name'].apply(lambda x: re.search(r'K\\[[^\\]]*\\]', x).start() + 1)\n",
    "\n",
    "print(df[['column_name', 'position']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"C[UNIMOD:4]M[UNIMOD:35]KM[UNIMOD:35]KK[UNIMOD:1896]KKKDD\"\n",
    "\n",
    "# Remove brackets and their contents, except for 'K[UNIMOD:26]' and 'K[UNIMOD:24]'\n",
    "output = re.sub(r'\\[UNIMOD:(?!1896|1884\\]).*?\\]', '', string)\n",
    "match = re.search(r'K(?=\\[UNIMOD:(?:1896|1884)\\])', output)\n",
    "if match:\n",
    "    position = match.start() + 1\n",
    "    print(position)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"KK[UNIMOD:1896]KKDD\"\n",
    "\n",
    "# Find the position of 'K' connected to '[UNIMOD:24]' or '[UNIMOD:26]'\n",
    "match = re.search(r'K(?=\\[UNIMOD:(?:1896|1884)\\])', string)\n",
    "\n",
    "if match:\n",
    "    position = match.start() + 1\n",
    "    print(position)\n",
    "else:\n",
    "    print(\"No match found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def find_crosslinker_position(peptide_sequence: str):\n",
    "    peptide_sequence = re.sub(r\"\\[UNIMOD:(?!1896|1884\\]).*?\\]\", \"\", peptide_sequence)\n",
    "    crosslinker_position = re.search(r\"K(?=\\[UNIMOD:(?:1896|1884)\\])\", peptide_sequence)\n",
    "    crosslinker_position = crosslinker_position.start() + 1\n",
    "    return crosslinker_position\n",
    "\n",
    "peptide_sequences = \"C[UNIMOD:4]M[UNIMOD:35]KM[UNIMOD:35]KK[UNIMOD:1884]KKKDD\"\n",
    "crosslinker_position = find_crosslinker_position(peptide_sequences)\n",
    "print(crosslinker_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y1+1', 'y1+2', 'y1+3', 'b1+1', 'b1+2', 'b1+3', 'y2+1', 'y2+2', 'y2+3', 'b2+1', 'b2+2', 'b2+3', 'y3+1', 'y3+2', 'y3+3', 'b3+1', 'b3+2', 'b3+3', 'y4+1', 'y4+2', 'y4+3', 'b4+1', 'b4+2', 'b4+3', 'y5+1', 'y5+2', 'y5+3', 'b5+1', 'b5+2', 'b5+3', 'y6+1', 'y6+2', 'y6+3', 'b6+1', 'b6+2', 'b6+3', 'y7+1', 'y7+2', 'y7+3', 'b7+1', 'b7+2', 'b7+3', 'y8+1', 'y8+2', 'y8+3', 'b8+1', 'b8+2', 'b8+3', 'y9+1', 'y9+2', 'y9+3', 'b9+1', 'b9+2', 'b9+3', 'y10+1', 'y10+2', 'y10+3', 'b10+1', 'b10+2', 'b10+3', 'y11+1', 'y11+2', 'y11+3', 'b11+1', 'b11+2', 'b11+3', 'y12+1', 'y12+2', 'y12+3', 'b12+1', 'b12+2', 'b12+3', 'y13+1', 'y13+2', 'y13+3', 'b13+1', 'b13+2', 'b13+3', 'y14+1', 'y14+2', 'y14+3', 'b14+1', 'b14+2', 'b14+3', 'y15+1', 'y15+2', 'y15+3', 'b15+1', 'b15+2', 'b15+3', 'y16+1', 'y16+2', 'y16+3', 'b16+1', 'b16+2', 'b16+3', 'y17+1', 'y17+2', 'y17+3', 'b17+1', 'b17+2', 'b17+3', 'y18+1', 'y18+2', 'y18+3', 'b18+1', 'b18+2', 'b18+3', 'y19+1', 'y19+2', 'y19+3', 'b19+1', 'b19+2', 'b19+3', 'y20+1', 'y20+2', 'y20+3', 'b20+1', 'b20+2', 'b20+3', 'y21+1', 'y21+2', 'y21+3', 'b21+1', 'b21+2', 'b21+3', 'y22+1', 'y22+2', 'y22+3', 'b22+1', 'b22+2', 'b22+3', 'y23+1', 'y23+2', 'y23+3', 'b23+1', 'b23+2', 'b23+3', 'y24+1', 'y24+2', 'y24+3', 'b24+1', 'b24+2', 'b24+3', 'y25+1', 'y25+2', 'y25+3', 'b25+1', 'b25+2', 'b25+3', 'y26+1', 'y26+2', 'y26+3', 'b26+1', 'b26+2', 'b26+3', 'y27+1', 'y27+2', 'y27+3', 'b27+1', 'b27+2', 'b27+3', 'y28+1', 'y28+2', 'y28+3', 'b28+1', 'b28+2', 'b28+3', 'y29+1', 'y29+2', 'y29+3', 'b29+1', 'b29+2', 'b29+3']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def gen_annotation_linear_pep():\n",
    "    ions = [\n",
    "        \"y\",\n",
    "        \"b\",\n",
    "    ]\n",
    "    charges = [\"1\", \"2\", \"3\"]\n",
    "    positions = [x for x in range(1, 30)]\n",
    "    annotation = []\n",
    "    for pos in positions:\n",
    "        for ion in ions:\n",
    "            for charge in charges:\n",
    "                annotation.append(ion + str(pos) + \"+\" + charge)\n",
    "    return annotation\n",
    "annotation = gen_annotation_linear_pep()\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y1+1' 'y1+2' 'y1+3' 'b_short_1+1' 'b_short_1+2' 'b_short_1+3' 'y2+1'\n",
      " 'y2+2' 'y2+3' 'b_short_2+1' 'b_short_2+2' 'b_short_2+3' 'y3+1' 'y3+2'\n",
      " 'y3+3' 'b_short_3+1' 'b_short_3+2' 'b_short_3+3' 'y4+1' 'y4+2' 'y4+3'\n",
      " 'b_short_4+1' 'b_short_4+2' 'b_short_4+3' 'y5+1' 'y5+2' 'y5+3'\n",
      " 'b_short_5+1' 'b_short_5+2' 'b_short_5+3' 'y6+1' 'y6+2' 'y6+3'\n",
      " 'b_short_6+1' 'b_short_6+2' 'b_short_6+3' 'y7+1' 'y7+2' 'y7+3'\n",
      " 'b_short_7+1' 'b_short_7+2' 'b_short_7+3' 'y8+1' 'y8+2' 'y8+3'\n",
      " 'b_short_8+1' 'b_short_8+2' 'b_short_8+3' 'y9+1' 'y9+2' 'y9+3'\n",
      " 'b_short_9+1' 'b_short_9+2' 'b_short_9+3' 'y10+1' 'y10+2' 'y10+3'\n",
      " 'b_short_10+1' 'b_short_10+2' 'b_short_10+3' 'y11+1' 'y11+2' 'y11+3'\n",
      " 'b_short_11+1' 'b_short_11+2' 'b_short_11+3' 'y12+1' 'y12+2' 'y12+3'\n",
      " 'b_short_12+1' 'b_short_12+2' 'b_short_12+3' 'y13+1' 'y13+2' 'y13+3'\n",
      " 'b_short_13+1' 'b_short_13+2' 'b_short_13+3' 'y14+1' 'y14+2' 'y14+3'\n",
      " 'b_short_14+1' 'b_short_14+2' 'b_short_14+3' 'y15+1' 'y15+2' 'y15+3'\n",
      " 'b_short_15+1' 'b_short_15+2' 'b_short_15+3' 'y16+1' 'y16+2' 'y16+3'\n",
      " 'b_short_16+1' 'b_short_16+2' 'b_short_16+3' 'y17+1' 'y17+2' 'y17+3'\n",
      " 'b_short_17+1' 'b_short_17+2' 'b_short_17+3' 'y18+1' 'y18+2' 'y18+3'\n",
      " 'b_short_18+1' 'b_short_18+2' 'b_short_18+3' 'y19+1' 'y19+2' 'y19+3'\n",
      " 'b_short_19+1' 'b_short_19+2' 'b_short_19+3' 'y20+1' 'y20+2' 'y20+3'\n",
      " 'b_short_20+1' 'b_short_20+2' 'b_short_20+3' 'y21+1' 'y21+2' 'y21+3'\n",
      " 'b_short_21+1' 'b_short_21+2' 'b_short_21+3' 'y22+1' 'y22+2' 'y22+3'\n",
      " 'b_short_22+1' 'b_short_22+2' 'b_short_22+3' 'y23+1' 'y23+2' 'y23+3'\n",
      " 'b_short_23+1' 'b_short_23+2' 'b_short_23+3' 'y24+1' 'y24+2' 'y24+3'\n",
      " 'b_short_24+1' 'b_short_24+2' 'b_short_24+3' 'y25+1' 'y25+2' 'y25+3'\n",
      " 'b_short_25+1' 'b_short_25+2' 'b_short_25+3' 'y26+1' 'y26+2' 'y26+3'\n",
      " 'b_short_26+1' 'b_short_26+2' 'b_short_26+3' 'y27+1' 'y27+2' 'y27+3'\n",
      " 'b_short_27+1' 'b_short_27+2' 'b_short_27+3' 'y28+1' 'y28+2' 'y28+3'\n",
      " 'b_short_28+1' 'b_short_28+2' 'b_short_28+3' 'y29+1' 'y29+2' 'y29+3'\n",
      " 'b_short_29+1' 'b_short_29+2' 'b_short_29+3' 'None' 'None' 'None'\n",
      " 'b_long_1+1' 'b_long_1+2' 'b_long_1+3' 'None' 'None' 'None' 'b_long_2+1'\n",
      " 'b_long_2+2' 'b_long_2+3' 'None' 'None' 'None' 'b_long_3+1' 'b_long_3+2'\n",
      " 'b_long_3+3' 'None' 'None' 'None' 'b_long_4+1' 'b_long_4+2' 'b_long_4+3'\n",
      " 'None' 'None' 'None' 'b_long_5+1' 'b_long_5+2' 'b_long_5+3' 'None' 'None'\n",
      " 'None' 'b_long_6+1' 'b_long_6+2' 'b_long_6+3' 'None' 'None' 'None'\n",
      " 'b_long_7+1' 'b_long_7+2' 'b_long_7+3' 'None' 'None' 'None' 'b_long_8+1'\n",
      " 'b_long_8+2' 'b_long_8+3' 'None' 'None' 'None' 'b_long_9+1' 'b_long_9+2'\n",
      " 'b_long_9+3' 'None' 'None' 'None' 'b_long_10+1' 'b_long_10+2'\n",
      " 'b_long_10+3' 'None' 'None' 'None' 'b_long_11+1' 'b_long_11+2'\n",
      " 'b_long_11+3' 'None' 'None' 'None' 'b_long_12+1' 'b_long_12+2'\n",
      " 'b_long_12+3' 'None' 'None' 'None' 'b_long_13+1' 'b_long_13+2'\n",
      " 'b_long_13+3' 'None' 'None' 'None' 'b_long_14+1' 'b_long_14+2'\n",
      " 'b_long_14+3' 'None' 'None' 'None' 'b_long_15+1' 'b_long_15+2'\n",
      " 'b_long_15+3' 'None' 'None' 'None' 'b_long_16+1' 'b_long_16+2'\n",
      " 'b_long_16+3' 'None' 'None' 'None' 'b_long_17+1' 'b_long_17+2'\n",
      " 'b_long_17+3' 'None' 'None' 'None' 'b_long_18+1' 'b_long_18+2'\n",
      " 'b_long_18+3' 'None' 'None' 'None' 'b_long_19+1' 'b_long_19+2'\n",
      " 'b_long_19+3' 'None' 'None' 'None' 'b_long_20+1' 'b_long_20+2'\n",
      " 'b_long_20+3' 'None' 'None' 'None' 'b_long_21+1' 'b_long_21+2'\n",
      " 'b_long_21+3' 'None' 'None' 'None' 'b_long_22+1' 'b_long_22+2'\n",
      " 'b_long_22+3' 'None' 'None' 'None' 'b_long_23+1' 'b_long_23+2'\n",
      " 'b_long_23+3' 'None' 'None' 'None' 'b_long_24+1' 'b_long_24+2'\n",
      " 'b_long_24+3' 'None' 'None' 'None' 'b_long_25+1' 'b_long_25+2'\n",
      " 'b_long_25+3' 'None' 'None' 'None' 'b_long_26+1' 'b_long_26+2'\n",
      " 'b_long_26+3' 'None' 'None' 'None' 'b_long_27+1' 'b_long_27+2'\n",
      " 'b_long_27+3' 'None' 'None' 'None' 'b_long_28+1' 'b_long_28+2'\n",
      " 'b_long_28+3' 'None' 'None' 'None' 'b_long_29+1' 'b_long_29+2'\n",
      " 'b_long_29+3']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def peak_pos_xl_cms2(unmod_seq: str, crosslinker_position: int) -> list:\n",
    "    \"\"\"\n",
    "    Determines the positions of all potential normal and xl fragments within the vector generated by generate_annotation_matrix.\n",
    "\n",
    "    This fuction is used only for cleavable crosslinked peptides.\n",
    "\n",
    "    :param unmod_seq: Un modified peptide sequence\n",
    "    :param crosslinker_position: The position of crosslinker\n",
    "    :raises ValueError: if Peptides exceeding a length of 30.\n",
    "    :return: position of diffrent fragments as list\n",
    "    \"\"\"\n",
    "    peaks_y = []\n",
    "    peaks_b = []\n",
    "    peaks_yshort = []\n",
    "    peaks_bshort = []\n",
    "    peaks_ylong = []\n",
    "    peaks_blong = []\n",
    "\n",
    "    if len(unmod_seq) < 31:\n",
    "        if crosslinker_position != 1:\n",
    "            peaks_b = np.array([3, 4, 5])\n",
    "            peaks_b = np.tile(peaks_b, crosslinker_position - 1) + np.repeat(np.arange(crosslinker_position - 1) * 6, 3)\n",
    "            first_pos_ylong = ((len(unmod_seq) - crosslinker_position) * 6) + 174  # fisrt  position for ylong\n",
    "            peaks_ylong = np.arange(first_pos_ylong, first_pos_ylong + 3)\n",
    "            peaks_ylong = np.tile(peaks_ylong, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "\n",
    "        if len(unmod_seq) != crosslinker_position:\n",
    "            peaks_y = [0, 1, 2]\n",
    "            peaks_y = np.tile(peaks_y, len(unmod_seq) - crosslinker_position) + np.repeat(\n",
    "                np.arange(len(unmod_seq) - crosslinker_position) * 6, 3\n",
    "            )\n",
    "            first_pos_blong = ((crosslinker_position - 1) * 6) + 174 + 3  # fisrt  position for blong\n",
    "            peaks_blong = [first_pos_blong, first_pos_blong + 1, first_pos_blong + 2]\n",
    "            peaks_blong = np.arange(first_pos_blong, first_pos_blong + 3)\n",
    "            peaks_blong = list(\n",
    "                np.tile(peaks_blong, len(unmod_seq) - crosslinker_position)\n",
    "                + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            )\n",
    "\n",
    "        peaks_yshort = [x - 174 for x in peaks_ylong]\n",
    "        peaks_bshort = [x - 174 for x in peaks_blong]\n",
    "        peaks_range = (\n",
    "            list(peaks_y)\n",
    "            + list(peaks_b)\n",
    "            + list(peaks_yshort)\n",
    "            + list(peaks_bshort)\n",
    "            + list(peaks_ylong)\n",
    "            + list(peaks_blong)\n",
    "        )\n",
    "        peaks_range.sort()\n",
    "    else:\n",
    "        raise ValueError(f\"Peptides exceeding a length of 30 are not supported: {len(unmod_seq)}\")\n",
    "\n",
    "    return peaks_range, peaks_y, peaks_b, peaks_yshort, peaks_bshort, peaks_ylong, peaks_blong\n",
    "\n",
    "def gen_annotation_linear_pep():\n",
    "    ions = [\n",
    "        \"y\",\n",
    "        \"b\",\n",
    "    ]\n",
    "    charges = [\"1\", \"2\", \"3\"]\n",
    "    positions = [x for x in range(1, 30)]\n",
    "    annotation = []\n",
    "    for pos in positions:\n",
    "        for ion in ions:\n",
    "            for charge in charges:\n",
    "                annotation.append(ion + str(pos) + \"+\" + charge)\n",
    "    return annotation\n",
    "\n",
    "def gen_annotation_xl(crosslinker_position: int):\n",
    "    annotations = gen_annotation_linear_pep()\n",
    "    annotation = np.concatenate((annotations, annotations))\n",
    "    annotation = annotation.tolist()\n",
    "    (\n",
    "        peaks_range,\n",
    "        peaks_y,\n",
    "        peaks_b,\n",
    "        peaks_yshort,\n",
    "        peaks_bshort,\n",
    "        peaks_ylong,\n",
    "        peaks_blong,\n",
    "    ) = peak_pos_xl_cms2(\"K\" * 30, crosslinker_position)\n",
    "    for pos in peaks_yshort:\n",
    "        annotation[pos] = \"y_short_\" + annotation[pos][1:]\n",
    "    for pos in peaks_bshort:\n",
    "        annotation[pos] = \"b_short_\" + annotation[pos][1:]\n",
    "    for pos in peaks_ylong:\n",
    "        annotation[pos] = \"y_long_\" + annotation[pos][1:]\n",
    "    for pos in peaks_blong:\n",
    "        annotation[pos] = \"b_long_\" + annotation[pos][1:]\n",
    "    pos_none = [num + 174 for num in peaks_y] + [num + 174 for num in peaks_b]\n",
    "    for pos in pos_none:\n",
    "        annotation[pos] = \"None\"\n",
    "    return np.array(annotation).astype(np.object_)\n",
    "\n",
    "annotation = gen_annotation_xl(1)\n",
    "print(annotation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEQ_LEN = 30  # Sequence length for prosit\n",
    "VEC_LENGTH = 174\n",
    "\n",
    "\n",
    "def create_masking(charges_array, sequences_lengths):\n",
    "    \"\"\"\n",
    "    assume reshaped output of prosit, shape sould be (num_seq, 174)\n",
    "    set filtered output where not allowed positions are set to -1\n",
    "    prosit output has the form:\n",
    "    y1+1 y1+2 y1+3 b1+1 b1+2 b1+3 y2+1     y2+2 y2+3     b2+1     b2+2 b2+3\n",
    "    if charge >= 3: all allowed\n",
    "    if charge == 2: all +3 invalid\n",
    "    if charge == 1: all +2 & +3 invalid\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(charges_array) == len(sequences_lengths)\n",
    "\n",
    "    mask = np.ones(shape=(len(charges_array), VEC_LENGTH), dtype=np.float16)\n",
    "\n",
    "    for i in range(len(charges_array)):\n",
    "        charge_one_hot = charges_array[i]\n",
    "        len_seq = sequences_lengths[i]\n",
    "        m = mask[i]\n",
    "\n",
    "        # filter according to peptide charge\n",
    "        if np.array_equal(charge_one_hot, [1, 0, 0, 0, 0, 0]):\n",
    "            invalid_indexes = [(x * 3 + 1) for x in range((SEQ_LEN - 1) * 2)] + [\n",
    "                (x * 3 + 2) for x in range((SEQ_LEN - 1) * 2)\n",
    "            ]\n",
    "            m[invalid_indexes] = np.nan\n",
    "\n",
    "        elif np.array_equal(charge_one_hot, [0, 1, 0, 0, 0, 0]):\n",
    "            invalid_indexes = [x * 3 + 2 for x in range((SEQ_LEN - 1) * 2)]\n",
    "            m[invalid_indexes] = np.nan\n",
    "\n",
    "        if len_seq < SEQ_LEN:\n",
    "            invalid_indexes = range((len_seq - 1) * 6, VEC_LENGTH)\n",
    "            m[invalid_indexes] = np.nan\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_masking(peaks, mask):\n",
    "    peaks[peaks < 0] = np.finfo(np.float32).eps\n",
    "    out = np.multiply(peaks, mask)\n",
    "    out = (out.T / np.nanmax(out, axis=1)).T\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y1+1' 'y1+2' 'y1+3' 'b1+1' 'b1+2' 'b1+3' 'y2+1' 'y2+2' 'y2+3' 'b2+1'\n",
      " 'b2+2' 'b2+3' 'y3+1' 'y3+2' 'y3+3' 'b3+1' 'b3+2' 'b3+3' 'y4+1' 'y4+2'\n",
      " 'y4+3' 'b4+1' 'b4+2' 'b4+3' 'y5+1' 'y5+2' 'y5+3' 'b5+1' 'b5+2' 'b5+3'\n",
      " 'y6+1' 'y6+2' 'y6+3' 'b6+1' 'b6+2' 'b6+3' 'y7+1' 'y7+2' 'y7+3' 'b7+1'\n",
      " 'b7+2' 'b7+3' 'y8+1' 'y8+2' 'y8+3' 'b8+1' 'b8+2' 'b8+3' 'y9+1' 'y9+2'\n",
      " 'y9+3' 'b9+1' 'b9+2' 'b9+3' 'y10+1' 'y10+2' 'y10+3' 'b10+1' 'b10+2'\n",
      " 'b10+3' 'y11+1' 'y11+2' 'y11+3' 'b11+1' 'b11+2' 'b11+3' 'y12+1' 'y12+2'\n",
      " 'y12+3' 'b12+1' 'b12+2' 'b12+3' 'y13+1' 'y13+2' 'y13+3' 'b13+1' 'b13+2'\n",
      " 'b13+3' 'y14+1' 'y14+2' 'y14+3' 'b14+1' 'b14+2' 'b14+3' 'y15+1' 'y15+2'\n",
      " 'y15+3' 'b15+1' 'b15+2' 'b15+3' 'y16+1' 'y16+2' 'y16+3' 'b16+1' 'b16+2'\n",
      " 'b16+3' 'y17+1' 'y17+2' 'y17+3' 'b17+1' 'b17+2' 'b17+3' 'y18+1' 'y18+2'\n",
      " 'y18+3' 'b18+1' 'b18+2' 'b18+3' 'y19+1' 'y19+2' 'y19+3' 'b19+1' 'b19+2'\n",
      " 'b19+3' 'y20+1' 'y20+2' 'y20+3' 'b20+1' 'b20+2' 'b20+3' 'y21+1' 'y21+2'\n",
      " 'y21+3' 'b21+1' 'b21+2' 'b21+3' 'y22+1' 'y22+2' 'y22+3' 'b22+1' 'b22+2'\n",
      " 'b22+3' 'y23+1' 'y23+2' 'y23+3' 'b23+1' 'b23+2' 'b23+3' 'y24+1' 'y24+2'\n",
      " 'y24+3' 'b24+1' 'b24+2' 'b24+3' 'y25+1' 'y25+2' 'y25+3' 'b25+1' 'b25+2'\n",
      " 'b25+3' 'y26+1' 'y26+2' 'y26+3' 'b26+1' 'b26+2' 'b26+3' 'y27+1' 'y27+2'\n",
      " 'y27+3' 'b27+1' 'b27+2' 'b27+3' 'y28+1' 'y28+2' 'y28+3' 'b28+1' 'b28+2'\n",
      " 'b28+3' 'y29+1' 'y29+2' 'y29+3' 'b29+1' 'b29+2' 'b29+3']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def gen_annotation():\n",
    "    ions = [\n",
    "        \"y\",\n",
    "        \"b\",\n",
    "    ]\n",
    "    charges = [1, 2, 3]\n",
    "    positions = [x for x in range(1, 30)]\n",
    "    annotation = []\n",
    "    for pos in positions:\n",
    "        for ion in ions:\n",
    "            for charge in charges:\n",
    "                annotation.append(f\"{ion}{pos}+{charge}\")\n",
    "    return np.array(annotation).astype(np.object_)\n",
    "t = gen_annotation()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def find_crosslinker_position(peptide_sequence: str):\n",
    "    peptide_sequence = re.sub(r\"\\[UNIMOD:(?!1896|1884\\]).*?\\]\", \"\", peptide_sequence)\n",
    "    crosslinker_position = re.search(r\"K(?=\\[UNIMOD:(?:1896|1884)\\])\", peptide_sequence)\n",
    "    crosslinker_position = crosslinker_position.start() + 1\n",
    "    return crosslinker_position\n",
    "\n",
    "peptide_sequence = \"AADDC[UNIMOD:4]K[UNIMOD:1896]KKMM\"\n",
    "print(find_crosslinker_position(peptide_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_short_1+1' 'y_short_1+2' 'y_short_1+3' 'b1+1' 'b1+2' 'b1+3'\n",
      " 'y_short_2+1' 'y_short_2+2' 'y_short_2+3' 'b2+1' 'b2+2' 'b2+3'\n",
      " 'y_short_3+1' 'y_short_3+2' 'y_short_3+3' 'b3+1' 'b3+2' 'b3+3'\n",
      " 'y_short_4+1' 'y_short_4+2' 'y_short_4+3' 'b4+1' 'b4+2' 'b4+3'\n",
      " 'y_short_5+1' 'y_short_5+2' 'y_short_5+3' 'b5+1' 'b5+2' 'b5+3'\n",
      " 'y_short_6+1' 'y_short_6+2' 'y_short_6+3' 'b6+1' 'b6+2' 'b6+3'\n",
      " 'y_short_7+1' 'y_short_7+2' 'y_short_7+3' 'b7+1' 'b7+2' 'b7+3'\n",
      " 'y_short_8+1' 'y_short_8+2' 'y_short_8+3' 'b8+1' 'b8+2' 'b8+3'\n",
      " 'y_short_9+1' 'y_short_9+2' 'y_short_9+3' 'b9+1' 'b9+2' 'b9+3'\n",
      " 'y_short_10+1' 'y_short_10+2' 'y_short_10+3' 'b10+1' 'b10+2' 'b10+3'\n",
      " 'y_short_11+1' 'y_short_11+2' 'y_short_11+3' 'b11+1' 'b11+2' 'b11+3'\n",
      " 'y_short_12+1' 'y_short_12+2' 'y_short_12+3' 'b12+1' 'b12+2' 'b12+3'\n",
      " 'y_short_13+1' 'y_short_13+2' 'y_short_13+3' 'b13+1' 'b13+2' 'b13+3'\n",
      " 'y_short_14+1' 'y_short_14+2' 'y_short_14+3' 'b14+1' 'b14+2' 'b14+3'\n",
      " 'y_short_15+1' 'y_short_15+2' 'y_short_15+3' 'b15+1' 'b15+2' 'b15+3'\n",
      " 'y_short_16+1' 'y_short_16+2' 'y_short_16+3' 'b16+1' 'b16+2' 'b16+3'\n",
      " 'y_short_17+1' 'y_short_17+2' 'y_short_17+3' 'b17+1' 'b17+2' 'b17+3'\n",
      " 'y_short_18+1' 'y_short_18+2' 'y_short_18+3' 'b18+1' 'b18+2' 'b18+3'\n",
      " 'y_short_19+1' 'y_short_19+2' 'y_short_19+3' 'b19+1' 'b19+2' 'b19+3'\n",
      " 'y_short_20+1' 'y_short_20+2' 'y_short_20+3' 'b20+1' 'b20+2' 'b20+3'\n",
      " 'y_short_21+1' 'y_short_21+2' 'y_short_21+3' 'b21+1' 'b21+2' 'b21+3'\n",
      " 'y_short_22+1' 'y_short_22+2' 'y_short_22+3' 'b22+1' 'b22+2' 'b22+3'\n",
      " 'y_short_23+1' 'y_short_23+2' 'y_short_23+3' 'b23+1' 'b23+2' 'b23+3'\n",
      " 'y_short_24+1' 'y_short_24+2' 'y_short_24+3' 'b24+1' 'b24+2' 'b24+3'\n",
      " 'y_short_25+1' 'y_short_25+2' 'y_short_25+3' 'b25+1' 'b25+2' 'b25+3'\n",
      " 'y_short_26+1' 'y_short_26+2' 'y_short_26+3' 'b26+1' 'b26+2' 'b26+3'\n",
      " 'y_short_27+1' 'y_short_27+2' 'y_short_27+3' 'b27+1' 'b27+2' 'b27+3'\n",
      " 'y_short_28+1' 'y_short_28+2' 'y_short_28+3' 'b28+1' 'b28+2' 'b28+3'\n",
      " 'y_short_29+1' 'y_short_29+2' 'y_short_29+3' 'b29+1' 'b29+2' 'b29+3'\n",
      " 'y_long_1+1' 'y_long_1+2' 'y_long_1+3' 'None' 'None' 'None' 'y_long_2+1'\n",
      " 'y_long_2+2' 'y_long_2+3' 'None' 'None' 'None' 'y_long_3+1' 'y_long_3+2'\n",
      " 'y_long_3+3' 'None' 'None' 'None' 'y_long_4+1' 'y_long_4+2' 'y_long_4+3'\n",
      " 'None' 'None' 'None' 'y_long_5+1' 'y_long_5+2' 'y_long_5+3' 'None' 'None'\n",
      " 'None' 'y_long_6+1' 'y_long_6+2' 'y_long_6+3' 'None' 'None' 'None'\n",
      " 'y_long_7+1' 'y_long_7+2' 'y_long_7+3' 'None' 'None' 'None' 'y_long_8+1'\n",
      " 'y_long_8+2' 'y_long_8+3' 'None' 'None' 'None' 'y_long_9+1' 'y_long_9+2'\n",
      " 'y_long_9+3' 'None' 'None' 'None' 'y_long_10+1' 'y_long_10+2'\n",
      " 'y_long_10+3' 'None' 'None' 'None' 'y_long_11+1' 'y_long_11+2'\n",
      " 'y_long_11+3' 'None' 'None' 'None' 'y_long_12+1' 'y_long_12+2'\n",
      " 'y_long_12+3' 'None' 'None' 'None' 'y_long_13+1' 'y_long_13+2'\n",
      " 'y_long_13+3' 'None' 'None' 'None' 'y_long_14+1' 'y_long_14+2'\n",
      " 'y_long_14+3' 'None' 'None' 'None' 'y_long_15+1' 'y_long_15+2'\n",
      " 'y_long_15+3' 'None' 'None' 'None' 'y_long_16+1' 'y_long_16+2'\n",
      " 'y_long_16+3' 'None' 'None' 'None' 'y_long_17+1' 'y_long_17+2'\n",
      " 'y_long_17+3' 'None' 'None' 'None' 'y_long_18+1' 'y_long_18+2'\n",
      " 'y_long_18+3' 'None' 'None' 'None' 'y_long_19+1' 'y_long_19+2'\n",
      " 'y_long_19+3' 'None' 'None' 'None' 'y_long_20+1' 'y_long_20+2'\n",
      " 'y_long_20+3' 'None' 'None' 'None' 'y_long_21+1' 'y_long_21+2'\n",
      " 'y_long_21+3' 'None' 'None' 'None' 'y_long_22+1' 'y_long_22+2'\n",
      " 'y_long_22+3' 'None' 'None' 'None' 'y_long_23+1' 'y_long_23+2'\n",
      " 'y_long_23+3' 'None' 'None' 'None' 'y_long_24+1' 'y_long_24+2'\n",
      " 'y_long_24+3' 'None' 'None' 'None' 'y_long_25+1' 'y_long_25+2'\n",
      " 'y_long_25+3' 'None' 'None' 'None' 'y_long_26+1' 'y_long_26+2'\n",
      " 'y_long_26+3' 'None' 'None' 'None' 'y_long_27+1' 'y_long_27+2'\n",
      " 'y_long_27+3' 'None' 'None' 'None' 'y_long_28+1' 'y_long_28+2'\n",
      " 'y_long_28+3' 'None' 'None' 'None' 'y_long_29+1' 'y_long_29+2'\n",
      " 'y_long_29+3' 'None' 'None' 'None']\n"
     ]
    }
   ],
   "source": [
    "def peak_pos_xl_cms2(unmod_seq: str, crosslinker_position: int) -> list:\n",
    "    \"\"\"\n",
    "    Determines the positions of all potential normal and xl fragments within the vector generated by generate_annotation_matrix.\n",
    "\n",
    "    This fuction is used only for cleavable crosslinked peptides.\n",
    "\n",
    "    :param unmod_seq: Un modified peptide sequence\n",
    "    :param crosslinker_position: The position of crosslinker\n",
    "    :raises ValueError: if Peptides exceeding a length of 30.\n",
    "    :return: position of diffrent fragments as list\n",
    "    \"\"\"\n",
    "    peaks_y = []\n",
    "    peaks_b = []\n",
    "    peaks_yshort = []\n",
    "    peaks_bshort = []\n",
    "    peaks_ylong = []\n",
    "    peaks_blong = []\n",
    "\n",
    "    if len(unmod_seq) < 31:\n",
    "        if crosslinker_position != 1:\n",
    "            peaks_b = np.array([3, 4, 5])\n",
    "            peaks_b = np.tile(peaks_b, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "            first_pos_ylong = (\n",
    "                (len(unmod_seq) - crosslinker_position) * 6\n",
    "            ) + 174  # fisrt  position for ylong\n",
    "            peaks_ylong = np.arange(first_pos_ylong, first_pos_ylong + 3)\n",
    "            peaks_ylong = np.tile(peaks_ylong, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "\n",
    "        if len(unmod_seq) != crosslinker_position:\n",
    "            peaks_y = [0, 1, 2]\n",
    "            peaks_y = np.tile(\n",
    "                peaks_y, len(unmod_seq) - crosslinker_position\n",
    "            ) + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            first_pos_blong = (\n",
    "                ((crosslinker_position - 1) * 6) + 174 + 3\n",
    "            )  # fisrt  position for blong\n",
    "            peaks_blong = [first_pos_blong, first_pos_blong + 1, first_pos_blong + 2]\n",
    "            peaks_blong = np.arange(first_pos_blong, first_pos_blong + 3)\n",
    "            peaks_blong = list(\n",
    "                np.tile(peaks_blong, len(unmod_seq) - crosslinker_position)\n",
    "                + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            )\n",
    "\n",
    "        peaks_yshort = [x - 174 for x in peaks_ylong]\n",
    "        peaks_bshort = [x - 174 for x in peaks_blong]\n",
    "        peaks_range = (\n",
    "            list(peaks_y)\n",
    "            + list(peaks_b)\n",
    "            + list(peaks_yshort)\n",
    "            + list(peaks_bshort)\n",
    "            + list(peaks_ylong)\n",
    "            + list(peaks_blong)\n",
    "        )\n",
    "        peaks_range.sort()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Peptides exceeding a length of 30 are not supported: {len(unmod_seq)}\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        peaks_range,\n",
    "        peaks_y,\n",
    "        peaks_b,\n",
    "        peaks_yshort,\n",
    "        peaks_bshort,\n",
    "        peaks_ylong,\n",
    "        peaks_blong,\n",
    "    )\n",
    "\n",
    "\n",
    "def gen_annotation_linear_pep():\n",
    "    ions = [\n",
    "        \"y\",\n",
    "        \"b\",\n",
    "    ]\n",
    "    charges = [\"1\", \"2\", \"3\"]\n",
    "    positions = [x for x in range(1, 30)]\n",
    "    annotation = []\n",
    "    for pos in positions:\n",
    "        for ion in ions:\n",
    "            for charge in charges:\n",
    "                annotation.append(ion + str(pos) + \"+\" + charge)\n",
    "    return annotation\n",
    "\n",
    "def gen_annotation_xl(crosslinker_position: int):\n",
    "    annotations = gen_annotation_linear_pep()\n",
    "    annotation = np.concatenate((annotations, annotations))\n",
    "    annotation = annotation.tolist()\n",
    "    (\n",
    "        peaks_range,\n",
    "        peaks_y,\n",
    "        peaks_b,\n",
    "        peaks_yshort,\n",
    "        peaks_bshort,\n",
    "        peaks_ylong,\n",
    "        peaks_blong,\n",
    "    ) = peak_pos_xl_cms2(\"K\" * 30, crosslinker_position)\n",
    "    for pos in peaks_yshort:\n",
    "        annotation[pos] = \"y_short_\" + annotation[pos][1:]\n",
    "    for pos in peaks_bshort:\n",
    "        annotation[pos] = \"b_short_\" + annotation[pos][1:]\n",
    "    for pos in peaks_ylong:\n",
    "        annotation[pos] = \"y_long_\" + annotation[pos][1:]\n",
    "    for pos in peaks_blong:\n",
    "        annotation[pos] = \"b_long_\" + annotation[pos][1:]\n",
    "    pos_none = [num + 174 for num in peaks_y] + [num + 174 for num in peaks_b]\n",
    "    for pos in pos_none:\n",
    "        annotation[pos] = \"None\"\n",
    "    return np.array(annotation).astype(np.object_)\n",
    "print(gen_annotation_xl(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['y1+1' 'y1+2' 'y1+3' 'b1+1' 'b1+2' 'b1+3' 'y2+1' 'y2+2' 'y2+3' 'b2+1'\n",
      "  'b2+2' 'b2+3' 'y3+1' 'y3+2' 'y3+3' 'b3+1' 'b3+2' 'b3+3' 'y4+1' 'y4+2'\n",
      "  'y4+3' 'b4+1' 'b4+2' 'b4+3' 'y5+1' 'y5+2' 'y5+3' 'b5+1' 'b5+2' 'b5+3'\n",
      "  'y6+1' 'y6+2' 'y6+3' 'b6+1' 'b6+2' 'b6+3' 'y7+1' 'y7+2' 'y7+3' 'b7+1'\n",
      "  'b7+2' 'b7+3' 'y8+1' 'y8+2' 'y8+3' 'b8+1' 'b8+2' 'b8+3' 'y9+1' 'y9+2'\n",
      "  'y9+3' 'b9+1' 'b9+2' 'b9+3' 'y10+1' 'y10+2' 'y10+3' 'b10+1' 'b10+2'\n",
      "  'b10+3' 'y11+1' 'y11+2' 'y11+3' 'b11+1' 'b11+2' 'b11+3' 'y12+1' 'y12+2'\n",
      "  'y12+3' 'b12+1' 'b12+2' 'b12+3' 'y13+1' 'y13+2' 'y13+3' 'b13+1' 'b13+2'\n",
      "  'b13+3' 'y14+1' 'y14+2' 'y14+3' 'b14+1' 'b14+2' 'b14+3' 'y15+1' 'y15+2'\n",
      "  'y15+3' 'b15+1' 'b15+2' 'b15+3' 'y16+1' 'y16+2' 'y16+3' 'b16+1' 'b16+2'\n",
      "  'b16+3' 'y17+1' 'y17+2' 'y17+3' 'b17+1' 'b17+2' 'b17+3' 'y18+1' 'y18+2'\n",
      "  'y18+3' 'b18+1' 'b18+2' 'b18+3' 'y19+1' 'y19+2' 'y19+3' 'b19+1' 'b19+2'\n",
      "  'b19+3' 'y20+1' 'y20+2' 'y20+3' 'b20+1' 'b20+2' 'b20+3' 'y21+1' 'y21+2'\n",
      "  'y21+3' 'b21+1' 'b21+2' 'b21+3' 'y22+1' 'y22+2' 'y22+3' 'b22+1' 'b22+2'\n",
      "  'b22+3' 'y23+1' 'y23+2' 'y23+3' 'b23+1' 'b23+2' 'b23+3' 'y24+1' 'y24+2'\n",
      "  'y24+3' 'b24+1' 'b24+2' 'b24+3' 'y25+1' 'y25+2' 'y25+3' 'b25+1' 'b25+2'\n",
      "  'b25+3' 'y26+1' 'y26+2' 'y26+3' 'b26+1' 'b26+2' 'b26+3' 'y27+1' 'y27+2'\n",
      "  'y27+3' 'b27+1' 'b27+2' 'b27+3' 'y28+1' 'y28+2' 'y28+3' 'b28+1' 'b28+2'\n",
      "  'b28+3' 'y29+1' 'y29+2' 'y29+3' 'b29+1' 'b29+2' 'b29+3']\n",
      " ['y1+1' 'y1+2' 'y1+3' 'b1+1' 'b1+2' 'b1+3' 'y2+1' 'y2+2' 'y2+3' 'b2+1'\n",
      "  'b2+2' 'b2+3' 'y3+1' 'y3+2' 'y3+3' 'b3+1' 'b3+2' 'b3+3' 'y4+1' 'y4+2'\n",
      "  'y4+3' 'b4+1' 'b4+2' 'b4+3' 'y5+1' 'y5+2' 'y5+3' 'b5+1' 'b5+2' 'b5+3'\n",
      "  'y6+1' 'y6+2' 'y6+3' 'b6+1' 'b6+2' 'b6+3' 'y7+1' 'y7+2' 'y7+3' 'b7+1'\n",
      "  'b7+2' 'b7+3' 'y8+1' 'y8+2' 'y8+3' 'b8+1' 'b8+2' 'b8+3' 'y9+1' 'y9+2'\n",
      "  'y9+3' 'b9+1' 'b9+2' 'b9+3' 'y10+1' 'y10+2' 'y10+3' 'b10+1' 'b10+2'\n",
      "  'b10+3' 'y11+1' 'y11+2' 'y11+3' 'b11+1' 'b11+2' 'b11+3' 'y12+1' 'y12+2'\n",
      "  'y12+3' 'b12+1' 'b12+2' 'b12+3' 'y13+1' 'y13+2' 'y13+3' 'b13+1' 'b13+2'\n",
      "  'b13+3' 'y14+1' 'y14+2' 'y14+3' 'b14+1' 'b14+2' 'b14+3' 'y15+1' 'y15+2'\n",
      "  'y15+3' 'b15+1' 'b15+2' 'b15+3' 'y16+1' 'y16+2' 'y16+3' 'b16+1' 'b16+2'\n",
      "  'b16+3' 'y17+1' 'y17+2' 'y17+3' 'b17+1' 'b17+2' 'b17+3' 'y18+1' 'y18+2'\n",
      "  'y18+3' 'b18+1' 'b18+2' 'b18+3' 'y19+1' 'y19+2' 'y19+3' 'b19+1' 'b19+2'\n",
      "  'b19+3' 'y20+1' 'y20+2' 'y20+3' 'b20+1' 'b20+2' 'b20+3' 'y21+1' 'y21+2'\n",
      "  'y21+3' 'b21+1' 'b21+2' 'b21+3' 'y22+1' 'y22+2' 'y22+3' 'b22+1' 'b22+2'\n",
      "  'b22+3' 'y23+1' 'y23+2' 'y23+3' 'b23+1' 'b23+2' 'b23+3' 'y24+1' 'y24+2'\n",
      "  'y24+3' 'b24+1' 'b24+2' 'b24+3' 'y25+1' 'y25+2' 'y25+3' 'b25+1' 'b25+2'\n",
      "  'b25+3' 'y26+1' 'y26+2' 'y26+3' 'b26+1' 'b26+2' 'b26+3' 'y27+1' 'y27+2'\n",
      "  'y27+3' 'b27+1' 'b27+2' 'b27+3' 'y28+1' 'y28+2' 'y28+3' 'b28+1' 'b28+2'\n",
      "  'b28+3' 'y29+1' 'y29+2' 'y29+3' 'b29+1' 'b29+2' 'b29+3']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def gen_annotation():\n",
    "    ions = [\n",
    "        \"y\",\n",
    "        \"b\",\n",
    "    ]\n",
    "    charges = [1, 2, 3]\n",
    "    positions = [x for x in range(1, 30)]\n",
    "    annotation = []\n",
    "    for pos in positions:\n",
    "        for ion in ions:\n",
    "            for charge in charges:\n",
    "                annotation.append(f\"{ion}{pos}+{charge}\")\n",
    "    return np.array(annotation).astype(np.object_)\n",
    "\n",
    "def gen_annotation_linear_pep():\n",
    "    ions = [\n",
    "        \"y\",\n",
    "        \"b\",\n",
    "    ]\n",
    "    charges = [\"1\", \"2\", \"3\"]\n",
    "    positions = [x for x in range(1, 30)]\n",
    "    annotation = []\n",
    "    for pos in positions:\n",
    "        for ion in ions:\n",
    "            for charge in charges:\n",
    "                annotation.append(ion + str(pos) + \"+\" + charge)\n",
    "    return annotation\n",
    "\n",
    "def gen_annotation_xl(crosslinker_position: int):\n",
    "    annotations = gen_annotation_linear_pep()\n",
    "    annotation = np.concatenate((annotations, annotations))\n",
    "    annotation = annotation.tolist()\n",
    "    (\n",
    "        peaks_range,\n",
    "        peaks_y,\n",
    "        peaks_b,\n",
    "        peaks_yshort,\n",
    "        peaks_bshort,\n",
    "        peaks_ylong,\n",
    "        peaks_blong,\n",
    "    ) = peak_pos_xl_cms2(\"K\" * 30, crosslinker_position)\n",
    "    for pos in peaks_yshort:\n",
    "        annotation[pos] = \"y_short_\" + annotation[pos][1:]\n",
    "    for pos in peaks_bshort:\n",
    "        annotation[pos] = \"b_short_\" + annotation[pos][1:]\n",
    "    for pos in peaks_ylong:\n",
    "        annotation[pos] = \"y_long_\" + annotation[pos][1:]\n",
    "    for pos in peaks_blong:\n",
    "        annotation[pos] = \"b_long_\" + annotation[pos][1:]\n",
    "    pos_none = [num + 174 for num in peaks_y] + [num + 174 for num in peaks_b]\n",
    "    for pos in pos_none:\n",
    "        annotation[pos] = \"None\"\n",
    "    return np.array(annotation).astype(np.object_)\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def peak_pos_xl_cms2(unmod_seq: str, crosslinker_position: int) -> list:\n",
    "    \"\"\"\n",
    "    Determines the positions of all potential normal and xl fragments within the vector generated by generate_annotation_matrix.\n",
    "\n",
    "    This fuction is used only for cleavable crosslinked peptides.\n",
    "\n",
    "    :param unmod_seq: Un modified peptide sequence\n",
    "    :param crosslinker_position: The position of crosslinker\n",
    "    :raises ValueError: if Peptides exceeding a length of 30.\n",
    "    :return: position of diffrent fragments as list\n",
    "    \"\"\"\n",
    "    peaks_y = []\n",
    "    peaks_b = []\n",
    "    peaks_yshort = []\n",
    "    peaks_bshort = []\n",
    "    peaks_ylong = []\n",
    "    peaks_blong = []\n",
    "\n",
    "    if len(unmod_seq) < 31:\n",
    "        if crosslinker_position != 1:\n",
    "            peaks_b = np.array([3, 4, 5])\n",
    "            peaks_b = np.tile(peaks_b, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "            first_pos_ylong = (\n",
    "                (len(unmod_seq) - crosslinker_position) * 6\n",
    "            ) + 174  # fisrt  position for ylong\n",
    "            peaks_ylong = np.arange(first_pos_ylong, first_pos_ylong + 3)\n",
    "            peaks_ylong = np.tile(peaks_ylong, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "\n",
    "        if len(unmod_seq) != crosslinker_position:\n",
    "            peaks_y = [0, 1, 2]\n",
    "            peaks_y = np.tile(\n",
    "                peaks_y, len(unmod_seq) - crosslinker_position\n",
    "            ) + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            first_pos_blong = (\n",
    "                ((crosslinker_position - 1) * 6) + 174 + 3\n",
    "            )  # fisrt  position for blong\n",
    "            peaks_blong = [first_pos_blong, first_pos_blong + 1, first_pos_blong + 2]\n",
    "            peaks_blong = np.arange(first_pos_blong, first_pos_blong + 3)\n",
    "            peaks_blong = list(\n",
    "                np.tile(peaks_blong, len(unmod_seq) - crosslinker_position)\n",
    "                + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            )\n",
    "\n",
    "        peaks_yshort = [x - 174 for x in peaks_ylong]\n",
    "        peaks_bshort = [x - 174 for x in peaks_blong]\n",
    "        peaks_range = (\n",
    "            list(peaks_y)\n",
    "            + list(peaks_b)\n",
    "            + list(peaks_yshort)\n",
    "            + list(peaks_bshort)\n",
    "            + list(peaks_ylong)\n",
    "            + list(peaks_blong)\n",
    "        )\n",
    "        peaks_range.sort()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Peptides exceeding a length of 30 are not supported: {len(unmod_seq)}\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        peaks_range,\n",
    "        peaks_y,\n",
    "        peaks_b,\n",
    "        peaks_yshort,\n",
    "        peaks_bshort,\n",
    "        peaks_ylong,\n",
    "        peaks_blong,\n",
    "    )\n",
    "\n",
    "\n",
    "def find_crosslinker_position(peptide_sequence: str):\n",
    "    peptide_sequence = re.sub(r\"\\[UNIMOD:(?!1896|1884\\]).*?\\]\", \"\", peptide_sequence)\n",
    "    crosslinker_position = re.search(r\"K(?=\\[UNIMOD:(?:1896|1884)\\])\", peptide_sequence)\n",
    "    crosslinker_position = crosslinker_position.start() + 1\n",
    "    return crosslinker_position\n",
    "\n",
    "#regular_sequence = [\"AAK[UNIMOD:1896]\",\"AAKKK[UNIMOD:1896]\"]\n",
    "annotation_1 = np.empty((0, 174))\n",
    "\n",
    "for i in range(2):\n",
    "                #crosslinker_position = find_crosslinker_position(regular_sequence[i])\n",
    "                annotation_i = gen_annotation()\n",
    "                annotation_1 = np.vstack((annotation_1, annotation_i))\n",
    "\n",
    "\n",
    "#annotation_2 = annotation = np.tile(gen_annotation(), 2).reshape((-1, 174))\n",
    "#annotation_2 = annotation = np.tile(gen_annotation_xl(1), 2).reshape((-1, 348))\n",
    "print(annotation_1)\n",
    "#print(annotation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 201 202 203 207 208 209 213 214 215 219 220 221 225 226 227 231 232 233\n",
      " 237 238 239 243 244 245 249 250 251 255 256 257 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   1.  1.  1. nan nan nan  1.  1.  1. nan nan nan  1.  1.  1. nan nan nan\n",
      "   1.  1.  1. nan nan nan  1.  1.  1. nan nan nan  1.  1.  1. nan nan nan\n",
      "   1.  1.  1. nan nan nan  1.  1.  1. nan nan nan  1.  1.  1. nan nan nan\n",
      "   1.  1.  1. nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# from spectrum_fundamentals.annotation.annotation import peak_pos_xl_cms2\n",
    "\n",
    "VEC_LENGTH = 348\n",
    "\n",
    "def peak_pos_xl_cms2(unmod_seq: str, crosslinker_position: int) -> list:\n",
    "    \"\"\"\n",
    "    Determines the positions of all potential normal and xl fragments within the vector generated by generate_annotation_matrix.\n",
    "\n",
    "    This fuction is used only for cleavable crosslinked peptides.\n",
    "\n",
    "    :param unmod_seq: Un modified peptide sequence\n",
    "    :param crosslinker_position: The position of crosslinker\n",
    "    :raises ValueError: if Peptides exceeding a length of 30.\n",
    "    :return: position of diffrent fragments as list\n",
    "    \"\"\"\n",
    "    peaks_y = []\n",
    "    peaks_b = []\n",
    "    peaks_yshort = []\n",
    "    peaks_bshort = []\n",
    "    peaks_ylong = []\n",
    "    peaks_blong = []\n",
    "\n",
    "    if len(unmod_seq) < 31:\n",
    "        if crosslinker_position != 1:\n",
    "            peaks_b = np.array([3, 4, 5])\n",
    "            peaks_b = np.tile(peaks_b, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "            first_pos_ylong = (\n",
    "                (len(unmod_seq) - crosslinker_position) * 6\n",
    "            ) + 174  # fisrt  position for ylong\n",
    "            peaks_ylong = np.arange(first_pos_ylong, first_pos_ylong + 3)\n",
    "            peaks_ylong = np.tile(peaks_ylong, crosslinker_position - 1) + np.repeat(\n",
    "                np.arange(crosslinker_position - 1) * 6, 3\n",
    "            )\n",
    "\n",
    "        if len(unmod_seq) != crosslinker_position:\n",
    "            peaks_y = [0, 1, 2]\n",
    "            peaks_y = np.tile(\n",
    "                peaks_y, len(unmod_seq) - crosslinker_position\n",
    "            ) + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            first_pos_blong = (\n",
    "                ((crosslinker_position - 1) * 6) + 174 + 3\n",
    "            )  # fisrt  position for blong\n",
    "            peaks_blong = [first_pos_blong, first_pos_blong + 1, first_pos_blong + 2]\n",
    "            peaks_blong = np.arange(first_pos_blong, first_pos_blong + 3)\n",
    "            peaks_blong = list(\n",
    "                np.tile(peaks_blong, len(unmod_seq) - crosslinker_position)\n",
    "                + np.repeat(np.arange(len(unmod_seq) - crosslinker_position) * 6, 3)\n",
    "            )\n",
    "\n",
    "        peaks_yshort = [x - 174 for x in peaks_ylong]\n",
    "        peaks_bshort = [x - 174 for x in peaks_blong]\n",
    "        peaks_range = (\n",
    "            list(peaks_y)\n",
    "            + list(peaks_b)\n",
    "            + list(peaks_yshort)\n",
    "            + list(peaks_bshort)\n",
    "            + list(peaks_ylong)\n",
    "            + list(peaks_blong)\n",
    "        )\n",
    "        peaks_range.sort()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Peptides exceeding a length of 30 are not supported: {len(unmod_seq)}\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        peaks_range,\n",
    "        peaks_y,\n",
    "        peaks_b,\n",
    "        peaks_yshort,\n",
    "        peaks_bshort,\n",
    "        peaks_ylong,\n",
    "        peaks_blong,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_masking(unmod_seq, crosslinker_position):\n",
    "    \"\"\"\n",
    "    assume reshaped output of xl-prosit, shape sould be (num_seq, 174 * 2)\n",
    "    set filtered output where not allowed positions are set to -1\n",
    "    we set charge = 2 for all peptide a and b\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(unmod_seq) == len(crosslinker_position)\n",
    "    mask = np.ones(shape=(len(unmod_seq), VEC_LENGTH))\n",
    "    for i in range(len(unmod_seq)):\n",
    "        m = mask[i].copy()\n",
    "        peaks_ranges = peak_pos_xl_cms2(unmod_seq[i], crosslinker_position[i])\n",
    "        updated_mask = np.setdiff1d(np.arange(0, 348), peaks_ranges[0])\n",
    "        updated_mask_charge_3 = np.arange(2, end + 348, 3)\n",
    "        updated_mask = np.concatenate((updated_mask, updated_mask_charge_3))\n",
    "        print(updated_mask)\n",
    "        m[updated_mask] = np.nan\n",
    "        mask[i] = m\n",
    "    return mask\n",
    "\n",
    "def find_crosslinker_position(peptide_sequence: str):\n",
    "    peptide_sequence = re.sub(r\"\\[UNIMOD:(?!1896|1884\\]).*?\\]\", \"\", peptide_sequence)\n",
    "    crosslinker_position = re.search(r\"K(?=\\[UNIMOD:(?:1896|1884)\\])\", peptide_sequence)\n",
    "    crosslinker_position = crosslinker_position.start() + 1\n",
    "    return crosslinker_position\n",
    "\n",
    "\n",
    "unmod_seq = [\"DIADAVTAAGVEVAKSEVR\"]\n",
    "crosslinker_position = [15]\n",
    "print(create_masking(unmod_seq,crosslinker_position))\n",
    "#print(find_crosslinker_position(\"DIADAVTAAGVEVAK[UNIMOD:1896]SEVR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
