# Documentation generation via jinja
swagger_tmpl.yml file contains the templatized version of swagger.yml. The parameters that need to be filled out in that template file are both from notes.yaml in the models directory and the back-end of the triton server.
The script that fills out the template is called `swagger_gen.py`


These are the parameters below given to the jinja template.
```python
 context = {'models': models,'triton_server_ip':reverse_host,'triton_server_port':reverse_port}
```
`models` is a dictionary object contains everything from `v2/models/{model}/config` endpoint and `notes.yaml`

One can access the specific model's notes via: ` models[i]['note'] `
One also can access the specific model's input/output tensor via: ` models[i]['input'] ` and `models[i]['output']`



# Logic of swagger_gen.py

`Swagger.yaml` generation is a service that runs before serving of the Swagger. This service waits until the Triton and Reverse proxy servers are up and running. There is a logic in the script where it sends request to the reverse proxy and if it doesn't get HTTP code between 200 and 299 it assumes the service is still starting up.

Upon getting the first 200 request the script stops waiting and sends request to the reverseproxy to identify the input/output tensors of the models that are whitelisted in `model_names.json` file. Once the script identifies those data, it proceeds to look into `notes.yaml` file stored under the path points in `model_names.json`.

The `notes.yaml` contains some information we could not store anywhere else such as description, summary, tag and example of the models.

The code generation. Only certain boilerplate parts of the code could be generated and huge chunk of the code had to be updated by the developers. The functions with boilerplate suffixes are the boilerplate generator.

## Header boilerplate
Essentially you could generate GRPC header boiler plate you have to define the URL, and port
`generate_grpc_header_boilierplate`
## Ouptut boilerplate
Then the output boilerplate where it generates a code where it appends the output tensor layers into a list.
The input could not be generated due to you have to give the special data to the service for each model and the types of the model had to be stored somewhere to be able to generate correct input data. 
`generate_append_output_boilerplate`

# Input boilerplate

In input initalization you need to define the input tensors, input type, and input size. These information came from the notes.yaml

## Result boilerplate
To get the result you have to send the input/output layer and store that information in result variable.
This can be generated by the function
`generate_output_boilerplate`

